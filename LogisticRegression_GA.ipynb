{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "bD8n0wlHfoNj",
    "outputId": "4b57a361-86b8-4f4c-fe9b-f2d1cc15bf5e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# NLTK for text mining\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Reviews.csv')\n",
    "\n",
    "#filling missing text\n",
    "df.Text.fillna('', inplace=True)\n",
    "df.Summary.fillna('', inplace=True)\n",
    "\n",
    "features = list(df.keys())\n",
    "features.remove('Score')\n",
    "target = 'Score'\n",
    "\n",
    "# Selecting 56 K reviews for faster testing\n",
    "# comment to apply to the whole data\n",
    "df, _, _, _ = train_test_split(df, df[target], test_size=0.90, random_state=42)\n",
    "\n",
    "\n",
    "# Stratified sampling to train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)\n",
    "#x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50249</th>\n",
       "      <td>50250</td>\n",
       "      <td>B000FBQ50I</td>\n",
       "      <td>A1SB8CXAUIKT8X</td>\n",
       "      <td>Rex N. Mills</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1184544000</td>\n",
       "      <td>Very Good!</td>\n",
       "      <td>Great texture and balance of sweet to butter i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94817</th>\n",
       "      <td>94818</td>\n",
       "      <td>B0029NM8KQ</td>\n",
       "      <td>A1X2KI19WPUN1B</td>\n",
       "      <td>Patricia C. Smith \"pspuddlejumper\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1316304000</td>\n",
       "      <td>My dog loves Cesar Grilled Chicken</td>\n",
       "      <td>I had looked for years for something that my d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305269</th>\n",
       "      <td>305270</td>\n",
       "      <td>B005PIJQC0</td>\n",
       "      <td>A1KSPYESOGAZ0I</td>\n",
       "      <td>Jon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1298505600</td>\n",
       "      <td>Good Hydrations</td>\n",
       "      <td>I've used Cytomax for the past couple of years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126046</th>\n",
       "      <td>126047</td>\n",
       "      <td>B001DWEFMS</td>\n",
       "      <td>A1XGFW5016CGQI</td>\n",
       "      <td>Cathio</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1301529600</td>\n",
       "      <td>FROSTING IS LIKE OLD FASHIONED HOME MADE</td>\n",
       "      <td>We just love these mixes. They are all delicio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445379</th>\n",
       "      <td>445380</td>\n",
       "      <td>B001JP7G4I</td>\n",
       "      <td>A102MAW3UT9B9P</td>\n",
       "      <td>Martin Alesia \"Marty 4242\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1344038400</td>\n",
       "      <td>Don't Buy!</td>\n",
       "      <td>dont waste your money. this is a piece of junk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId  \\\n",
       "50249    50250  B000FBQ50I  A1SB8CXAUIKT8X   \n",
       "94817    94818  B0029NM8KQ  A1X2KI19WPUN1B   \n",
       "305269  305270  B005PIJQC0  A1KSPYESOGAZ0I   \n",
       "126046  126047  B001DWEFMS  A1XGFW5016CGQI   \n",
       "445379  445380  B001JP7G4I  A102MAW3UT9B9P   \n",
       "\n",
       "                               ProfileName  HelpfulnessNumerator  \\\n",
       "50249                         Rex N. Mills                     3   \n",
       "94817   Patricia C. Smith \"pspuddlejumper\"                     1   \n",
       "305269                                 Jon                     0   \n",
       "126046                              Cathio                     0   \n",
       "445379          Martin Alesia \"Marty 4242\"                     0   \n",
       "\n",
       "        HelpfulnessDenominator  Score        Time  \\\n",
       "50249                        3      5  1184544000   \n",
       "94817                        1      5  1316304000   \n",
       "305269                       0      5  1298505600   \n",
       "126046                       0      5  1301529600   \n",
       "445379                       0      1  1344038400   \n",
       "\n",
       "                                         Summary  \\\n",
       "50249                                 Very Good!   \n",
       "94817         My dog loves Cesar Grilled Chicken   \n",
       "305269                           Good Hydrations   \n",
       "126046  FROSTING IS LIKE OLD FASHIONED HOME MADE   \n",
       "445379                                Don't Buy!   \n",
       "\n",
       "                                                     Text  \n",
       "50249   Great texture and balance of sweet to butter i...  \n",
       "94817   I had looked for years for something that my d...  \n",
       "305269  I've used Cytomax for the past couple of years...  \n",
       "126046  We just love these mixes. They are all delicio...  \n",
       "445379  dont waste your money. this is a piece of junk...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56845, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper class for text preprocessing\n",
    "- Remove some noise figures.\n",
    "- Apply lemmatization then stemming\n",
    "- Apply TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aD1jluPcl_LZ"
   },
   "outputs": [],
   "source": [
    "class text_processor():\n",
    "\n",
    "    def __init__(self, max_features=None):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        self.special = {'<br />':' ', \"n't\":' not '}\n",
    "        self.digits = {' 0 ': ' zero ', ' 1 ': ' one ', ' 2 ':' two ', ' 3 ': ' three ', ' 4 ':' four ',\n",
    "                  ' 5 ': ' five ', ' 6 ': ' six ', ' 7 ':' seven ', ' 8 ':' eight ', ' 9 ':' nine ', ' 10 ':' ten '}\n",
    "        \n",
    "        self.stop_words = set(['the','a','an','and', 'this','that','these','those','then','through','about','for','is','of','during'])\n",
    "\n",
    "    def clean(self, text):\n",
    "        text = str(text)\n",
    "\n",
    "        for key, value in self.special.items():\n",
    "            text = text.replace(key, value)\n",
    "        for key, value in self.digits.items():\n",
    "            text = text.replace(key, value)\n",
    "\n",
    "        text = text.lower() \n",
    "        text = re.sub(r\"[^a-z]\", \" \", text) #Get rid of emoticons \n",
    "        text = [self.stemmer.stem(self.lemmatizer.lemmatize(w)) for w in text.split() if not w in self.stop_words]\n",
    "        text = ' '.join(text)\n",
    "\n",
    "        return text\n",
    "\n",
    "\n",
    "    def fit(self, series):\n",
    "        text = series.apply(self.clean)\n",
    "        self.vectorizer.fit(text)\n",
    "\n",
    "    \n",
    "    def transform(self, series):\n",
    "        text = series.apply(self.clean)\n",
    "        return self.vectorizer.transform(text)\n",
    "    \n",
    "    def fit_transform(self, series):\n",
    "        text = series.apply(self.clean)\n",
    "        self.vectorizer.fit(text)\n",
    "        return self.vectorizer.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yuwJglb0m9Ht"
   },
   "outputs": [],
   "source": [
    "p = text_processor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ejqh8OezY8qd"
   },
   "source": [
    "#### Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GDvtLF8P6DiS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "\n",
      "\n",
      "100759    This product is no better than any other bottl...\n",
      "312773    I gave this as a gift with Kuchen Meister Limo...\n",
      "428583    My lab goes wild for these and I am almost tem...\n",
      "221341    So a friend of mine from Japan who I have been...\n",
      "280790    These peanut bars are the very best around. Th...\n",
      "138851    Spilled my bottle on the floor and my dog lick...\n",
      "560704    Oh, this is some good cat food!<br />Have you ...\n",
      "165815    I ordered these beans back in December to make...\n",
      "168484    Senseo recently released several flavored vari...\n",
      "488507    I Bake these cookie and like them but I can do...\n",
      "157255    I ENJOYED THE COMPLEATS CAUSE WAS QUICK AND EA...\n",
      "427111    Up until this week, I have LOVED Rockstar Juic...\n",
      "307750    Just bought this when we ran out of our usual ...\n",
      "404514    This is a great cereal for gluten free diets o...\n",
      "175786    For many months very few stores have been stoc...\n",
      "400961    I obtained this product because we have cats a...\n",
      "429199    This is the Best canned Clam Chowder that I ha...\n",
      "244369    I love the convenience that these pouches offe...\n",
      "436077    The French cheese assortment is amazing. A sel...\n",
      "243549    My goodness the price of  Gold  is really up h...\n",
      "206549    The product came on time and was exactly what ...\n",
      "58326     Please consider this request.<br />We need ama...\n",
      "318372    My dogs have loved this product for 22+ Years....\n",
      "542445    This is excellent tea..  I'm glad it's organic...\n",
      "214048    130 calories for the bag and it's pretty full ...\n",
      "396548    Received the product exactly as described.  Su...\n",
      "282989    I order this 10 pound box of jelly bellys and ...\n",
      "369142    Since I cannot eat sugar, and there are so few...\n",
      "501145    I never knew there could be such a difference ...\n",
      "511637    What makes for a good pistachio is size, fresh...\n",
      "                                ...                        \n",
      "334302    I thoroughly enjoyed a package of these fig ba...\n",
      "139667    My cat is fussy-and I wondered if she would li...\n",
      "2919      I absolutely love the Oreo Thin Crisps cookies...\n",
      "88437     Timothy coffee is my favorite brand of K-Cups....\n",
      "353817    The cans were in good condition and the green ...\n",
      "38578     I love love love the Torani Sugar-Free Syrups ...\n",
      "402889    This product is really great. It has a good te...\n",
      "335482    I love these little power boosts for the turn....\n",
      "27134     Bought these at Whole Foods to try....and the ...\n",
      "368821    These bars are the best health bars I've ever ...\n",
      "346807    If you like flavored coffee, especially chocol...\n",
      "265956    This tea is full of flavor! We make it without...\n",
      "441511    This product was purchased to help someone who...\n",
      "535314    I was thrilled to see that Amazon had started ...\n",
      "247129    I received a cactus \"stick\" a little over six ...\n",
      "196274    If you like french roast, you'll like this one...\n",
      "358315    My son has an acid reflux issue since 10 weeks...\n",
      "134607    It's not steak sauce or pepper sauce. The flav...\n",
      "447498    Since receiving these delicious hemp seed hear...\n",
      "356241    This product has a great flavor to it.  It's b...\n",
      "551384    I have used this sauce for my Pad Thai for ove...\n",
      "218277    Can't believe how good this is!  Just got it a...\n",
      "563359    I received the oatmeal raisin cookie in my mom...\n",
      "64807     I originally purchased this for my kids but th...\n",
      "401702    I did not care for this product.  It has littl...\n",
      "314925    Just new to the sprout eaters club. I mixed th...\n",
      "121921    Good Li Hing Mui.  What every Hawaiian away fr...\n",
      "295951    I really like this product.  The electrolyte w...\n",
      "338563    I received a Keurig machine for Christmas and ...\n",
      "385777    I never follow the recipe and prepared this ho...\n",
      "Name: Text, Length: 45476, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#for text in x_train['Text']:\n",
    " #   print(\"Type\", type(text))\n",
    "  #  print(\"\\n\")\n",
    "   # print(text)\n",
    "    #print(\"\\n\")\n",
    "x_text = p.fit_transform(x_train['Text'])\n",
    "xt_text = p.transform(x_test['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n2ihCnqcY1J0"
   },
   "source": [
    "#### Preprocess summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SeLDSxihWKsf"
   },
   "outputs": [],
   "source": [
    "x_summary = p.fit_transform(x_train['Summary'])\n",
    "xt_summary = p.transform(x_test['Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse concatenation to add other features to the rather than text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = hstack([x_text, x_summary, x_train.Time.values.reshape(-1,1), x_train.HelpfulnessNumerator.values.reshape(-1,1), x_train.HelpfulnessDenominator.values.reshape(-1,1)])\n",
    "xt = hstack([xt_text, xt_summary, x_test.Time.values.reshape(-1,1), x_test.HelpfulnessNumerator.values.reshape(-1,1), x_test.HelpfulnessDenominator.values.reshape(-1,1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seelecting 1000 features only as TFIDF produce high number of features\n",
    "selector = SelectKBest(chi2, k=1000) ###Select the most highly correlated features based on chi2 (statistical test for a significance of a feature)\n",
    "x_train = selector.fit_transform(x, y_train)\n",
    "x_test = selector.transform(xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logistic regression without Kmeans or Gentic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 0.639568123846\n",
      "Test accuracy 0.636555545782\n"
     ]
    }
   ],
   "source": [
    "RF = LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\", n_jobs=-1)\n",
    "RF.fit(x_train, y_train)\n",
    "\n",
    "pred = RF.predict(x_train)\n",
    "print('Training accuracy', accuracy_score(y_train, pred))\n",
    "\n",
    "pred = RF.predict(x_test)\n",
    "print('Test accuracy', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logistic regression with Kmeans only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 0.639568123846\n",
      "Test accuracy 0.636555545782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Taking 5 clusters through k means\n",
    "n_clusters = len(np.unique(y_train))\n",
    "clf = KMeans(n_clusters = n_clusters, random_state=42)\n",
    "clf.fit(x_train)\n",
    "y_labels_train = clf.labels_\n",
    "y_labels_test = clf.predict(x_test)\n",
    "\n",
    "# add the new labels as new features to the input\n",
    "x_train = np.hstack([x_train.toarray(),y_labels_train.reshape((-1,1))]) ###We add the new k-means labels to the original features\n",
    "x_test =  np.hstack([x_test.toarray(),y_labels_test.reshape((-1,1))])\n",
    "\n",
    "RF2 = LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\", n_jobs=-1)\n",
    "RF2.fit(x_train, y_train)\n",
    "\n",
    "pred = RF2.predict(x_train)\n",
    "print('Training accuracy', accuracy_score(y_train, pred))\n",
    "\n",
    "pred = RF2.predict(x_test)\n",
    "print('Test accuracy', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logistic regression + GA feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seelecting 1000 features only as TFIDF produce high number of features\n",
    "selector = SelectKBest(chi2, k=1000)\n",
    "x_train = selector.fit_transform(x, y_train) ####Test data must be hidden, during feature selection calculation \n",
    "#xv = selector.transform(xv)\n",
    "x_test = selector.transform(xt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# taken from git+https://github.com/manuel-calzolari/sklearn-genetic.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                  \tstd                        \tmin              \tmax              \n",
      "0  \t50    \t[-10000.      505.46]\t[  0.          14.13960395]\t[-10000.    473.]\t[-10000.    551.]\n",
      "1  \t34    \t[-10000.      496.58]\t[  0.          14.13236003]\t[-10000.    458.]\t[-10000.    542.]\n",
      "2  \t34    \t[-10000.      487.04]\t[  0.          12.27022412]\t[-10000.    458.]\t[-10000.    516.]\n",
      "3  \t23    \t[-10000.      476.56]\t[  0.          12.04518161]\t[-10000.    454.]\t[-10000.    505.]\n",
      "4  \t30    \t[-10000.      465.32]\t[  0.          10.74139656]\t[-10000.    446.]\t[-10000.    489.]\n",
      "5  \t32    \t[-10000.      456.12]\t[ 0.          7.64104705]  \t[-10000.    436.]\t[-10000.    476.]\n",
      "6  \t29    \t[-10000.      451.64]\t[ 0.          8.40180933]  \t[-10000.    432.]\t[-10000.    476.]\n",
      "7  \t34    \t[-10000.      447.26]\t[ 0.          7.11564474]  \t[-10000.    428.]\t[-10000.    466.]\n",
      "8  \t29    \t[-10000.      442.92]\t[ 0.          9.33775134]  \t[-10000.    419.]\t[-10000.    463.]\n",
      "9  \t30    \t[-10000.     433.5]  \t[ 0.          9.32148057]  \t[-10000.    414.]\t[-10000.    451.]\n",
      "10 \t38    \t[-10000.      428.94]\t[ 0.          8.83495331]  \t[-10000.    412.]\t[-10000.    447.]\n",
      "11 \t28    \t[-10000.      422.46]\t[ 0.          6.65495304]  \t[-10000.    412.]\t[-10000.    438.]\n",
      "12 \t36    \t[-10000.      419.12]\t[ 0.          6.76650575]  \t[-10000.    409.]\t[-10000.    438.]\n",
      "13 \t27    \t[-10000.      415.52]\t[ 0.          9.19617312]  \t[-10000.    395.]\t[-10000.    437.]\n",
      "14 \t35    \t[-10000.      411.24]\t[ 0.          9.12043859]  \t[-10000.    392.]\t[-10000.    434.]\n",
      "15 \t26    \t[-10000.     405.4]  \t[ 0.          8.30180703]  \t[-10000.    386.]\t[-10000.    430.]\n",
      "16 \t32    \t[-10000.      399.06]\t[ 0.          7.07222737]  \t[-10000.    384.]\t[-10000.    418.]\n",
      "17 \t35    \t[-10000.      397.08]\t[ 0.          9.60174984]  \t[-10000.    374.]\t[-10000.    425.]\n",
      "18 \t33    \t[-10000.      390.88]\t[ 0.          9.38006397]  \t[-10000.    371.]\t[-10000.    415.]\n",
      "19 \t27    \t[-10000.      385.78]\t[ 0.          6.88851218]  \t[-10000.    374.]\t[-10000.    400.]\n",
      "20 \t34    \t[-10000.     383.9]  \t[ 0.         9.0934042]    \t[-10000.    362.]\t[-10000.    408.]\n",
      "21 \t29    \t[-10000.      379.44]\t[ 0.          8.50919503]  \t[-10000.    362.]\t[-10000.    405.]\n",
      "22 \t32    \t[-10000.      375.76]\t[  0.          10.84354186]\t[-10000.    359.]\t[-10000.    399.]\n",
      "23 \t26    \t[-10000.      368.08]\t[ 0.          7.71968911]  \t[-10000.    356.]\t[-10000.    390.]\n",
      "24 \t38    \t[-10000.      365.78]\t[ 0.          8.85954852]  \t[-10000.    342.]\t[-10000.    388.]\n",
      "25 \t30    \t[-10000.      361.64]\t[ 0.          9.25799114]  \t[-10000.    342.]\t[-10000.    383.]\n",
      "26 \t24    \t[-10000.      355.08]\t[ 0.          8.57867123]  \t[-10000.    340.]\t[-10000.    385.]\n",
      "27 \t27    \t[-10000.      354.62]\t[ 0.          8.02717883]  \t[-10000.    342.]\t[-10000.    372.]\n",
      "28 \t32    \t[-10000.      351.46]\t[ 0.          8.50461051]  \t[-10000.    342.]\t[-10000.    378.]\n",
      "29 \t34    \t[-10000.      349.44]\t[  0.          10.31340875]\t[-10000.    329.]\t[-10000.    374.]\n",
      "30 \t29    \t[-10000.      345.76]\t[ 0.          9.20773588]  \t[-10000.    329.]\t[-10000.    375.]\n",
      "31 \t29    \t[-10000.      342.34]\t[ 0.         8.0786385]    \t[-10000.    329.]\t[-10000.    365.]\n",
      "32 \t28    \t[-10000.      340.82]\t[ 0.          9.61600749]  \t[-10000.    329.]\t[-10000.    368.]\n",
      "33 \t28    \t[-10000.      338.76]\t[ 0.          9.96907217]  \t[-10000.    323.]\t[-10000.    366.]\n",
      "34 \t35    \t[-10000.     335.3]  \t[ 0.          8.55160804]  \t[-10000.    316.]\t[-10000.    356.]\n",
      "35 \t33    \t[-10000.     332.7]  \t[ 0.          8.58894638]  \t[-10000.    316.]\t[-10000.    358.]\n",
      "36 \t30    \t[-10000.      330.94]\t[ 0.          9.57582372]  \t[-10000.    316.]\t[-10000.    362.]\n",
      "37 \t30    \t[-10000.      325.38]\t[ 0.         7.3099658]    \t[-10000.    315.]\t[-10000.    348.]\n",
      "38 \t33    \t[-10000.      322.52]\t[ 0.          7.61114972]  \t[-10000.    313.]\t[-10000.    348.]\n",
      "39 \t39    \t[-10000.      322.24]\t[ 0.          8.49131321]  \t[-10000.    308.]\t[-10000.    342.]\n",
      "40 \t22    \t[-10000.      317.18]\t[ 0.          7.19358047]  \t[-10000.    304.]\t[-10000.    345.]\n",
      "Training accuracy 0.681040548861\n",
      "Test accuracy 0.675433195532\n"
     ]
    }
   ],
   "source": [
    "from genetic_selection import GeneticSelectionCV\n",
    "RF3 = LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\")\n",
    "GA       = GeneticSelectionCV(RF3,\n",
    "                              cv=5,\n",
    "                              verbose=1,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=20,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)\n",
    "selector = GA.fit(x_train, y_train)\n",
    "\n",
    "pred = GA.predict(x_train)\n",
    "print('Training accuracy', accuracy_score(y_train, pred))\n",
    "\n",
    "pred = GA.predict(x_test)\n",
    "print('Test accuracy', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logistic regression + GA feature selection + Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting 1000 features only as TFIDF produce high number of features\n",
    "selector = SelectKBest(chi2, k=1000)\n",
    "x_train = selector.fit_transform(x, y_train)\n",
    "x_test = selector.transform(xt)\n",
    "\n",
    "# add the new labels of kmeans as new features to the input\n",
    "x_train = np.hstack([x_train.toarray(),y_labels_train.reshape((-1,1))])\n",
    "x_test =  np.hstack([x_test.toarray(),y_labels_test.reshape((-1,1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = sparse.csr_matrix(x_train)\n",
    "x_test = sparse.csr_matrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                  \tstd                        \tmin              \tmax              \n",
      "0  \t50    \t[-10000.      500.72]\t[  0.          13.10731094]\t[-10000.    469.]\t[-10000.    529.]\n",
      "1  \t35    \t[-10000.     488.9]  \t[  0.          14.51654229]\t[-10000.    451.]\t[-10000.    516.]\n",
      "2  \t24    \t[-10000.      477.28]\t[  0.          13.14844477]\t[-10000.    451.]\t[-10000.    518.]\n",
      "3  \t34    \t[-10000.      466.48]\t[  0.          11.66917306]\t[-10000.    440.]\t[-10000.    492.]\n",
      "4  \t26    \t[-10000.      457.94]\t[ 0.          8.59164711]  \t[-10000.    437.]\t[-10000.    475.]\n",
      "5  \t24    \t[-10000.      451.86]\t[ 0.          9.31452629]  \t[-10000.    425.]\t[-10000.    474.]\n",
      "6  \t31    \t[-10000.      446.52]\t[ 0.          9.66072461]  \t[-10000.    425.]\t[-10000.    472.]\n",
      "7  \t27    \t[-10000.      439.88]\t[ 0.          7.46361843]  \t[-10000.    425.]\t[-10000.    457.]\n",
      "8  \t33    \t[-10000.      435.02]\t[ 0.          7.31160721]  \t[-10000.    421.]\t[-10000.    461.]\n",
      "9  \t32    \t[-10000.      430.24]\t[ 0.         6.5377672]    \t[-10000.    417.]\t[-10000.    453.]\n",
      "10 \t34    \t[-10000.      428.34]\t[ 0.          7.76043813]  \t[-10000.    413.]\t[-10000.    443.]\n",
      "11 \t23    \t[-10000.      422.66]\t[ 0.          7.13192821]  \t[-10000.    403.]\t[-10000.    447.]\n",
      "12 \t30    \t[-10000.      417.82]\t[ 0.          7.16851449]  \t[-10000.    400.]\t[-10000.    438.]\n",
      "13 \t33    \t[-10000.      413.38]\t[ 0.          6.88735072]  \t[-10000.    396.]\t[-10000.    433.]\n",
      "14 \t33    \t[-10000.     409.7]  \t[ 0.          8.71378219]  \t[-10000.    395.]\t[-10000.    436.]\n",
      "15 \t27    \t[-10000.     403.6]  \t[ 0.          6.39374695]  \t[-10000.    392.]\t[-10000.    417.]\n",
      "16 \t31    \t[-10000.     399.7]  \t[ 0.          6.17494939]  \t[-10000.    388.]\t[-10000.    423.]\n",
      "17 \t37    \t[-10000.      397.92]\t[ 0.          7.24110489]  \t[-10000.    382.]\t[-10000.    415.]\n",
      "18 \t31    \t[-10000.      395.52]\t[ 0.         7.6347626]    \t[-10000.    382.]\t[-10000.    419.]\n",
      "19 \t24    \t[-10000.      390.28]\t[ 0.          6.03668783]  \t[-10000.    378.]\t[-10000.    411.]\n",
      "20 \t30    \t[-10000.      387.12]\t[ 0.         6.1891518]    \t[-10000.    378.]\t[-10000.    403.]\n",
      "21 \t25    \t[-10000.      383.76]\t[ 0.          7.46072383]  \t[-10000.    371.]\t[-10000.    416.]\n",
      "22 \t27    \t[-10000.      380.88]\t[ 0.          6.28852924]  \t[-10000.    372.]\t[-10000.    399.]\n",
      "23 \t24    \t[-10000.      377.68]\t[ 0.          6.10062292]  \t[-10000.    368.]\t[-10000.    403.]\n",
      "24 \t26    \t[-10000.      375.42]\t[ 0.          5.77958476]  \t[-10000.    368.]\t[-10000.    396.]\n",
      "25 \t30    \t[-10000.      374.22]\t[ 0.          5.36018656]  \t[-10000.    366.]\t[-10000.    392.]\n",
      "26 \t32    \t[-10000.      372.34]\t[ 0.          6.56539412]  \t[-10000.    355.]\t[-10000.    392.]\n",
      "27 \t36    \t[-10000.      370.66]\t[ 0.          8.28881174]  \t[-10000.    355.]\t[-10000.    393.]\n",
      "28 \t35    \t[-10000.     366.8]  \t[ 0.          6.93974063]  \t[-10000.    348.]\t[-10000.    387.]\n",
      "29 \t31    \t[-10000.      361.12]\t[ 0.          6.53801193]  \t[-10000.    348.]\t[-10000.    386.]\n",
      "30 \t32    \t[-10000.      358.12]\t[ 0.          7.94893704]  \t[-10000.    347.]\t[-10000.    381.]\n",
      "31 \t34    \t[-10000.      354.24]\t[ 0.          6.44844167]  \t[-10000.    342.]\t[-10000.    374.]\n",
      "32 \t20    \t[-10000.      351.24]\t[ 0.          5.08157456]  \t[-10000.    340.]\t[-10000.    364.]\n",
      "33 \t23    \t[-10000.      350.02]\t[ 0.          7.35252338]  \t[-10000.    340.]\t[-10000.    372.]\n",
      "34 \t35    \t[-10000.      347.96]\t[ 0.          6.48370265]  \t[-10000.    337.]\t[-10000.    370.]\n",
      "35 \t27    \t[-10000.      345.46]\t[ 0.          6.61879143]  \t[-10000.    335.]\t[-10000.    367.]\n",
      "36 \t26    \t[-10000.      342.04]\t[ 0.          7.54707891]  \t[-10000.    333.]\t[-10000.    367.]\n",
      "37 \t29    \t[-10000.     341.2]  \t[ 0.          8.87017474]  \t[-10000.    331.]\t[-10000.    366.]\n",
      "38 \t40    \t[-10000.      339.74]\t[ 0.          7.97197592]  \t[-10000.    329.]\t[-10000.    359.]\n",
      "39 \t30    \t[-10000.      337.08]\t[ 0.          8.01957605]  \t[-10000.    329.]\t[-10000.    364.]\n",
      "40 \t27    \t[-10000.      334.64]\t[ 0.          7.02783039]  \t[-10000.    326.]\t[-10000.    357.]\n",
      "Training accuracy 0.68860497845\n",
      "Test accuracy 0.678511742458\n"
     ]
    }
   ],
   "source": [
    "selector = GA.fit(x_train, y_train)\n",
    "\n",
    "pred = GA.predict(x_train)\n",
    "print('Training accuracy', accuracy_score(y_train, pred))\n",
    "\n",
    "pred = GA.predict(x_test)\n",
    "print('Test accuracy', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def comment_to_rating(text, GA):\n",
    " #   text = [text]\n",
    "  #  text = pd.Series(text)\n",
    "   # print(type(text))\n",
    "    #print(text)\n",
    "    #pre_process = text_processor()\n",
    "    #x_text = pre_process.transform(text)\n",
    "    #return GA.predict(x_text)\n",
    "#text = \"Iâ€™ve been buying ACV for several months both from amazon and other stores but the order I received today is either not the real apple cider vinegar or is a faulty batch. The colour is different and much darker. The taste is different and tastes more like malt vinegar. And the mother should be strands of strings not clump of sand. Not impressed and will cancel my subscription for this item.\"\n",
    "#print(\"Rating\", comment_to_rating(text, GA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Ejqh8OezY8qd",
    "c7qrXY2lZRlm"
   ],
   "name": "data_mining.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
